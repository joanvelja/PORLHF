{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davisfoote/opt/anaconda3/envs/assisting_bounded_humans/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import imageio\n",
    "import torch as th\n",
    "import tqdm\n",
    "\n",
    "from imitation_modules import NonImageCnnRewardNet\n",
    "from stealing_gridworld import StealingGridworld\n",
    "from value_iteration import get_optimal_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enumerating states: 100%|██████████| 25/25 [00:04<00:00,  5.61it/s]\n",
      "Value iteration: 100%|██████████| 30/30 [00:01<00:00, 22.99it/s]\n",
      "Value iteration: 100%|██████████| 30/30 [00:01<00:00, 23.26it/s]\n"
     ]
    }
   ],
   "source": [
    "visibilities = [\"full\", \"partial\"]\n",
    "model_paths = [\n",
    "    \"saved_reward_models/full-vis_scalar_reward_model_5_32,32_3_20230425_011443/latest_checkpoint.pt\",\n",
    "    \"saved_reward_models/partial-vis_scalar_reward_model_5_32,32_3_20230424_210742/latest_checkpoint.pt\",\n",
    "]\n",
    "\n",
    "GRID_SIZE = 5\n",
    "HORIZON = 30\n",
    "\n",
    "HID_CHANNELS = (32, 32)\n",
    "KERNEL_SIZE = 3\n",
    "\n",
    "\n",
    "visibility_mask = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "\n",
    "env = StealingGridworld(\n",
    "    grid_size=GRID_SIZE,\n",
    "    max_steps=HORIZON,\n",
    "    reward_for_depositing=100,\n",
    "    reward_for_picking_up=1,\n",
    "    reward_for_stealing=-200,\n",
    ")\n",
    "\n",
    "\n",
    "def load_model_params(model_path):\n",
    "    reward_net = NonImageCnnRewardNet(\n",
    "        env.observation_space,\n",
    "        env.action_space,\n",
    "        hid_channels=HID_CHANNELS,\n",
    "        kernel_size=KERNEL_SIZE,\n",
    "    )\n",
    "    model_state_dict = th.load(model_path, map_location=th.device('cpu'))\n",
    "    reward_net.load_state_dict(model_state_dict)\n",
    "    return reward_net\n",
    "\n",
    "\n",
    "reward_nets = [load_model_params(model_path) for model_path in model_paths]\n",
    "policies = [get_optimal_policy(env, alt_reward_fn=reward_net) for reward_net in reward_nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and size PNGs per entity\n",
    "\n",
    "img_dir = \"presentation/images/stealy_dan\"\n",
    "\n",
    "GRID_CELL_IMAGE_SHAPE = (400, 400, 4)\n",
    "\n",
    "def pad_image_to_shape(image, bias=\"right\", shape=GRID_CELL_IMAGE_SHAPE):\n",
    "    missing_rows = shape[0] - image.shape[0]\n",
    "    missing_cols = shape[1] - image.shape[1]\n",
    "    top_pad = missing_rows // 2\n",
    "    bottom_pad = missing_rows - top_pad\n",
    "    if bias == \"left\":\n",
    "        left_pad = missing_cols // 12\n",
    "        right_pad = missing_cols - left_pad\n",
    "    elif bias == \"right\":\n",
    "        right_pad = missing_cols // 12\n",
    "        left_pad = missing_cols - right_pad\n",
    "    return np.pad(image, ((top_pad, bottom_pad), (left_pad, right_pad), (0, 0)), mode=\"constant\")\n",
    "\n",
    "\n",
    "# Load PNGs for each entity\n",
    "agent_pngs = [pad_image_to_shape(plt.imread(f\"{img_dir}/agent_{i}.png\"), bias=\"left\") for i in range(4)]\n",
    "free_pellet_png = pad_image_to_shape(plt.imread(f\"{img_dir}/free_pellet.png\"))\n",
    "owned_pellet_png = pad_image_to_shape(plt.imread(f\"{img_dir}/owned_pellet.png\"))\n",
    "home_png = pad_image_to_shape(plt.imread(f\"{img_dir}/home.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_state(state, visibility_mask=None):\n",
    "    grid_size = state.shape[1]\n",
    "\n",
    "    opacity_mask = np.ones((grid_size, grid_size))\n",
    "    opacity_mask[np.where(visibility_mask == 0)] = 0.5\n",
    "\n",
    "    full_grid = np.zeros((grid_size * GRID_CELL_IMAGE_SHAPE[0], grid_size * GRID_CELL_IMAGE_SHAPE[1], 4))\n",
    "    full_grid[:, :] = [0.7, 1.0, 0.7, 1.0]\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            cell = state[:, i, j]\n",
    "            cell_png = np.zeros(GRID_CELL_IMAGE_SHAPE)\n",
    "            if cell[0] == 1:\n",
    "                cell_png += agent_pngs[cell[-1]]\n",
    "            if cell[1] == 1:\n",
    "                cell_png += free_pellet_png\n",
    "            if cell[2] == 1:\n",
    "                cell_png += owned_pellet_png\n",
    "            if cell[3] == 1:\n",
    "                cell_png += home_png\n",
    "            # Only overwrite pixels that are not transparent\n",
    "            full_grid[\n",
    "                i * GRID_CELL_IMAGE_SHAPE[0] : (i + 1) * GRID_CELL_IMAGE_SHAPE[0],\n",
    "                j * GRID_CELL_IMAGE_SHAPE[1] : (j + 1) * GRID_CELL_IMAGE_SHAPE[1],\n",
    "                :,\n",
    "            ] = np.where(cell_png[..., -1:] > 0, cell_png, full_grid[\n",
    "                i * GRID_CELL_IMAGE_SHAPE[0] : (i + 1) * GRID_CELL_IMAGE_SHAPE[0],\n",
    "                j * GRID_CELL_IMAGE_SHAPE[1] : (j + 1) * GRID_CELL_IMAGE_SHAPE[1],\n",
    "                :,\n",
    "            ])\n",
    "            if visibility_mask is not None:\n",
    "                full_grid[\n",
    "                    i * GRID_CELL_IMAGE_SHAPE[0] : (i + 1) * GRID_CELL_IMAGE_SHAPE[0],\n",
    "                    j * GRID_CELL_IMAGE_SHAPE[1] : (j + 1) * GRID_CELL_IMAGE_SHAPE[1],\n",
    "                    :,\n",
    "                ] *= opacity_mask[i, j]\n",
    "\n",
    "    # Draw the grid lines\n",
    "    thickness = 3\n",
    "    for i in range(grid_size):\n",
    "        full_grid[i * GRID_CELL_IMAGE_SHAPE[0], :, :] = 0\n",
    "        full_grid[i * GRID_CELL_IMAGE_SHAPE[0] - thickness : i * GRID_CELL_IMAGE_SHAPE[0] + thickness, :, :] = 0\n",
    "        full_grid[:, i * GRID_CELL_IMAGE_SHAPE[1], :] = 0\n",
    "        full_grid[:, i * GRID_CELL_IMAGE_SHAPE[1] - thickness : i * GRID_CELL_IMAGE_SHAPE[1] + thickness, :] = 0\n",
    "    # Outer border\n",
    "    full_grid[:thickness*2, :, :] = 0\n",
    "    full_grid[-thickness*2:, :, :] = 0\n",
    "    full_grid[:, :thickness*2, :] = 0\n",
    "    full_grid[:, -thickness*2:, :] = 0\n",
    "\n",
    "    return full_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_from_states(states, output_file, visibility_mask=None, frame_rate=4):\n",
    "    pil_images = []\n",
    "    for state in states:\n",
    "        image = get_image_from_state(state, visibility_mask)\n",
    "        image = (image[:, :, :3] * 255).astype(np.uint8)\n",
    "        pil_images.append(Image.fromarray(image))\n",
    "    if len(pil_images) == 1:\n",
    "        pil_images[0].save(output_file)\n",
    "    else:\n",
    "        pil_images[0].save(\n",
    "            output_file,\n",
    "            save_all=True,\n",
    "            append_images=pil_images[1:],\n",
    "            duration=int(1000 / frame_rate),\n",
    "            loop=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stills_dir = \"presentation/images/env_stills\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.pellet_locations = {\n",
    "    \"free\": np.array([[2, 3], [3, 2]]),\n",
    "    \"owned\": np.array([[4, 3]]),\n",
    "}\n",
    "env.agent_position = np.array([1, 2])\n",
    "save_image_from_states([env._get_observation()], f\"{stills_dir}/explain_env.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.pellet_locations = {\n",
    "    \"free\": np.array([]),\n",
    "    \"owned\": np.array([[4, 3]]),\n",
    "}\n",
    "env.num_carried_pellets = 1\n",
    "save_image_from_states([env._get_observation()], f\"{stills_dir}/good_action.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.pellet_locations = {\n",
    "    \"free\": np.array([]),\n",
    "    \"owned\": np.array([[1, 3]]),\n",
    "}\n",
    "env.agent_position = np.array([1, 3])\n",
    "save_image_from_states([env._get_observation()], f\"{stills_dir}/bad_action.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.pellet_locations = {\n",
    "    \"free\": np.array([]),\n",
    "    \"owned\": np.array([[4, 3]]),\n",
    "}\n",
    "env.agent_position = np.array([4, 3])\n",
    "save_image_from_states([env._get_observation()], f\"{stills_dir}/bad_action_hidden.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.pellet_locations = {\n",
    "    \"free\": np.array([]),\n",
    "    \"owned\": np.array([]),\n",
    "}\n",
    "save_image_from_states([env._get_observation()], f\"{stills_dir}/masked.png\", visibility_mask=visibility_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_dir = \"presentation/videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollouts for evaluation: 100%|██████████| 1000/1000 [00:05<00:00, 184.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, {StoleVisiblePellet: 0.0, FailedToPickUpFreePellet: 0.0, FailedToDepositPellet: 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollouts for evaluation: 100%|██████████| 1000/1000 [00:06<00:00, 148.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.086, {StoleVisiblePellet: 0.0, DidntStealInvisiblePellet: 0.053, FailedToPickUpFreePellet: 0.072, FailedToDepositPellet: 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluate_reward_model import full_visibility_evaluator_factory, partial_visibility_evaluator_factory\n",
    "\n",
    "full_vis_evaluator = full_visibility_evaluator_factory()\n",
    "partial_vis_evaluator = partial_visibility_evaluator_factory(visibility_mask)\n",
    "\n",
    "# These evaluate that the policies behave as expected (not necesarily optimally).\n",
    "# Everything should be 0 or close to 0.\n",
    "print(full_vis_evaluator.evaluate(policies[0], env, num_trajs=1000))\n",
    "print(partial_vis_evaluator.evaluate(policies[1], env, num_trajs=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"{videos_dir}/well_behaved.gif\"\n",
    "\n",
    "num_rollouts = 5\n",
    "\n",
    "trajs = [env.rollout_with_policy(policies[0], render=False) for _ in range(num_rollouts)]\n",
    "\n",
    "states = []\n",
    "for traj in trajs:\n",
    "    states.extend(traj.obs)\n",
    "\n",
    "save_image_from_states(states, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"{videos_dir}/stealing_off_cam.gif\"\n",
    "output_file_masked = f\"{videos_dir}/stealing_off_cam_masked.gif\"\n",
    "\n",
    "num_rollouts = 5\n",
    "\n",
    "trajs = [env.rollout_with_policy(policies[1], render=False) for _ in range(num_rollouts)]\n",
    "\n",
    "states = []\n",
    "for traj in trajs:\n",
    "    states.extend(traj.obs)\n",
    "\n",
    "save_image_from_states(states, output_file_masked, visibility_mask=visibility_mask)\n",
    "save_image_from_states(states, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assisting_bounded_humans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
